# PyWebCrawler
当我觉得会爬网站是个不错的技能点后，就做了这个项目。  
个人计划做一套，然后放树莓派上，爬一下有x气、x点小说、x易音乐之类的，或者爬一下电影网站。  
因为放树莓派上，下载资源就不计划了，但“断点续爬”应该值得攻克一下。毕竟那么个小派，爬得慢，不小心断了只能从头开始也太无趣了。
  
## 项目结构
首先这是使用Python，利用Scrapy做的一套爬虫“框架”，设计思路是：有一个主入口，有两三套站点结构，两三套页面规则（分别放在类似website的文件夹里）。通过配置项，组合出适合的爬虫。理想情况下若遇到网站改版，只需稍微改动`dwLoader.py`就能快速适应调整。

## 还缺什么？
需要在website文件夹里创建一个`url_setting.py`的文件。里面设置三个变量：
```python
target_url= ['http://test.abc/123.html']    #入口网址 一般是开始爬的起点，如新闻列表、论坛帖子列表、作品电影网站预览目录等

allowed_domains= ['test.abc']               #允许爬到域名范围，具体看Scrapy关于allowed_domains的要求

scheme = "http://"                          #访问协议类型 dwLoader.py 里翻页若用到的是相对地址，则用这些拼接下一页地址
```
  
## 待攻克问题
* [ ] 断点续爬
* [ ] 存储到数据库或其他更优方案
* [ ] 生成查看页面——或许是基于node+vue的一个小静态网站
* [ ] 资源整理系统——既然做了资源站，那给资源分类，打标签，改错别字之类的应该要支持
* [ ] 爬动态DOM的网站